{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73c65c6",
   "metadata": {},
   "source": [
    "Download the test dataset from Kaggle and merge it with your current data set.\n",
    "\n",
    "Split your dataset into a training dataset from 01.07.2013 to 31.07.2017, a validation dataset from 01.08.2017 to 31.07.2018, and the test set from 01.08.2018 to 31.07.2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c139920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n",
      "Test dataset shape: (1830, 3)\n",
      "Merged bakery dataset shape: (10119, 9)\n",
      "\n",
      "Test dataset columns:\n",
      "['id', 'Datum', 'Warengruppe']\n",
      "\n",
      "Merged bakery dataset columns:\n",
      "['id', 'date', 'Warengruppe', 'umsatz', 'KielerWoche', 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit', 'Wettercode']\n",
      "\n",
      "First few rows of test dataset:\n",
      "        id       Datum  Warengruppe\n",
      "0  1808011  2018-08-01            1\n",
      "1  1808021  2018-08-02            1\n",
      "2  1808031  2018-08-03            1\n",
      "3  1808041  2018-08-04            1\n",
      "4  1808051  2018-08-05            1\n",
      "\n",
      "First few rows of merged bakery dataset:\n",
      "   id        date  Warengruppe  umsatz  KielerWoche  Bewoelkung  Temperatur  \\\n",
      "0 NaN  2012-01-01          NaN     NaN          NaN         8.0      9.8250   \n",
      "1 NaN  2012-01-02          NaN     NaN          NaN         7.0      7.4375   \n",
      "2 NaN  2012-01-03          NaN     NaN          NaN         8.0      5.5375   \n",
      "3 NaN  2012-01-04          NaN     NaN          NaN         4.0      5.6875   \n",
      "4 NaN  2012-01-05          NaN     NaN          NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode  \n",
      "0                 14.0        58.0  \n",
      "1                 12.0         NaN  \n",
      "2                 18.0        63.0  \n",
      "3                 19.0        80.0  \n",
      "4                 23.0        80.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "test_df = pd.read_csv('test.csv')\n",
    "merged_bakery_df = pd.read_csv('data/merged_bakery.csv')\n",
    "\n",
    "# Display basic info about each dataset\n",
    "print(f\"\\nTest dataset shape: {test_df.shape}\")\n",
    "print(f\"Merged bakery dataset shape: {merged_bakery_df.shape}\")\n",
    "\n",
    "print(\"\\nTest dataset columns:\")\n",
    "print(test_df.columns.tolist())\n",
    "\n",
    "print(\"\\nMerged bakery dataset columns:\")\n",
    "print(merged_bakery_df.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst few rows of test dataset:\")\n",
    "print(test_df.head())\n",
    "\n",
    "print(\"\\nFirst few rows of merged bakery dataset:\")\n",
    "print(merged_bakery_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6a78e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data for merging...\n",
      "Test data date range: 2018-08-01 00:00:00 to 2019-07-30 00:00:00\n",
      "Merged bakery data date range: 2012-01-01 00:00:00 to 2019-08-01 00:00:00\n",
      "\n",
      "Test data after merging with weather: (1830, 9)\n",
      "Sample of merged test data:\n",
      "        id       date  Warengruppe  umsatz  KielerWoche  Bewoelkung  \\\n",
      "0  1808011 2018-08-01            1     NaN          NaN         0.0   \n",
      "1  1808021 2018-08-02            1     NaN          NaN         0.0   \n",
      "2  1808031 2018-08-03            1     NaN          NaN         1.0   \n",
      "3  1808041 2018-08-04            1     NaN          NaN         4.0   \n",
      "4  1808051 2018-08-05            1     NaN          NaN         7.0   \n",
      "\n",
      "   Temperatur  Windgeschwindigkeit  Wettercode  \n",
      "0     23.7625                 10.0         0.0  \n",
      "1     26.1875                 10.0         0.0  \n",
      "2     27.6625                 10.0         0.0  \n",
      "3     25.1375                 12.0         NaN  \n",
      "4     21.3000                 14.0        61.0  \n"
     ]
    }
   ],
   "source": [
    "# Prepare test data for merging\n",
    "print(\"Preparing test data for merging...\")\n",
    "\n",
    "# Rename 'Datum' to 'date' in test dataset to match merged_bakery_df\n",
    "test_df_prepared = test_df.copy()\n",
    "test_df_prepared = test_df_prepared.rename(columns={'Datum': 'date'})\n",
    "\n",
    "# Convert date columns to datetime for both datasets\n",
    "test_df_prepared['date'] = pd.to_datetime(test_df_prepared['date'])\n",
    "merged_bakery_df['date'] = pd.to_datetime(merged_bakery_df['date'])\n",
    "\n",
    "print(f\"Test data date range: {test_df_prepared['date'].min()} to {test_df_prepared['date'].max()}\")\n",
    "print(f\"Merged bakery data date range: {merged_bakery_df['date'].min()} to {merged_bakery_df['date'].max()}\")\n",
    "\n",
    "# For test data, we don't have sales (umsatz) data - this will be what we predict\n",
    "# Add placeholder columns for test data to match structure\n",
    "test_df_prepared['umsatz'] = np.nan  # This is what we want to predict\n",
    "\n",
    "# Merge weather data from merged_bakery_df to test_df_prepared based on date\n",
    "weather_columns = ['date', 'KielerWoche', 'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit', 'Wettercode']\n",
    "weather_data = merged_bakery_df[weather_columns].drop_duplicates(subset=['date'])\n",
    "\n",
    "# Merge test data with weather data\n",
    "test_df_merged = pd.merge(test_df_prepared, weather_data, on='date', how='left')\n",
    "\n",
    "print(f\"\\nTest data after merging with weather: {test_df_merged.shape}\")\n",
    "print(\"Sample of merged test data:\")\n",
    "print(test_df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca34a3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all datasets...\n",
      "Historical data (after removing NaN): (9334, 9)\n",
      "Historical data date range: 2013-07-01 00:00:00 to 2018-07-31 00:00:00\n",
      "Combined dataset shape: (11164, 9)\n",
      "Combined data date range: 2013-07-01 00:00:00 to 2019-07-30 00:00:00\n",
      "\n",
      "Split ranges:\n",
      "Training: 2013-07-01 to 2017-07-31\n",
      "Validation: 2017-08-01 to 2018-07-31\n",
      "Test: 2018-08-01 to 2019-07-31\n"
     ]
    }
   ],
   "source": [
    "# Combine the historical data with the test data\n",
    "print(\"Combining all datasets...\")\n",
    "\n",
    "# Filter out rows with NaN values in important columns from merged_bakery_df for training\n",
    "historical_data = merged_bakery_df.dropna(subset=['Warengruppe', 'umsatz']).copy()\n",
    "\n",
    "print(f\"Historical data (after removing NaN): {historical_data.shape}\")\n",
    "print(f\"Historical data date range: {historical_data['date'].min()} to {historical_data['date'].max()}\")\n",
    "\n",
    "# Combine historical data and test data\n",
    "all_data = pd.concat([historical_data, test_df_merged], ignore_index=True)\n",
    "all_data = all_data.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {all_data.shape}\")\n",
    "print(f\"Combined data date range: {all_data['date'].min()} to {all_data['date'].max()}\")\n",
    "\n",
    "# Define date ranges for splitting\n",
    "train_start = pd.to_datetime('2013-07-01')\n",
    "train_end = pd.to_datetime('2017-07-31')\n",
    "val_start = pd.to_datetime('2017-08-01') \n",
    "val_end = pd.to_datetime('2018-07-31')\n",
    "test_start = pd.to_datetime('2018-08-01')\n",
    "test_end = pd.to_datetime('2019-07-31')\n",
    "\n",
    "print(f\"\\nSplit ranges:\")\n",
    "print(f\"Training: {train_start.date()} to {train_end.date()}\")\n",
    "print(f\"Validation: {val_start.date()} to {val_end.date()}\")\n",
    "print(f\"Test: {test_start.date()} to {test_end.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29e9e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train, validation, and test sets...\n",
      "\n",
      "Dataset splits:\n",
      "Training set: 7493 samples (2013-07-01 to 2017-07-31)\n",
      "Validation set: 1841 samples (2017-08-01 to 2018-07-31)\n",
      "Test set: 1830 samples (2018-08-01 to 2019-07-30)\n",
      "\n",
      "Missing umsatz values:\n",
      "Training set: 0 / 7493\n",
      "Validation set: 0 / 1841\n",
      "Test set: 1830 / 1830 (expected - these are prediction targets)\n",
      "\n",
      "Sample from training set:\n",
      "          id       date  Warengruppe      umsatz  KielerWoche  Bewoelkung  \\\n",
      "0  1307015.0 2013-07-01          5.0  317.475875          NaN         6.0   \n",
      "1  1307014.0 2013-07-01          4.0   65.890169          NaN         6.0   \n",
      "2  1307012.0 2013-07-01          2.0  535.856285          NaN         6.0   \n",
      "\n",
      "   Temperatur  Windgeschwindigkeit  Wettercode  \n",
      "0     17.8375                 15.0        20.0  \n",
      "1     17.8375                 15.0        20.0  \n",
      "2     17.8375                 15.0        20.0  \n",
      "\n",
      "Sample from validation set:\n",
      "             id       date  Warengruppe      umsatz  KielerWoche  Bewoelkung  \\\n",
      "7493  1708015.0 2017-08-01          5.0  325.864228          NaN         6.0   \n",
      "7494  1708014.0 2017-08-01          4.0   88.208006          NaN         6.0   \n",
      "7495  1708013.0 2017-08-01          3.0  294.872701          NaN         6.0   \n",
      "\n",
      "      Temperatur  Windgeschwindigkeit  Wettercode  \n",
      "7493      21.375                  7.0        21.0  \n",
      "7494      21.375                  7.0        21.0  \n",
      "7495      21.375                  7.0        21.0  \n",
      "\n",
      "Sample from test set:\n",
      "             id       date  Warengruppe  umsatz  KielerWoche  Bewoelkung  \\\n",
      "9334  1808011.0 2018-08-01          1.0     NaN          NaN         0.0   \n",
      "9335  1808012.0 2018-08-01          2.0     NaN          NaN         0.0   \n",
      "9336  1808013.0 2018-08-01          3.0     NaN          NaN         0.0   \n",
      "\n",
      "      Temperatur  Windgeschwindigkeit  Wettercode  \n",
      "9334     23.7625                 10.0         0.0  \n",
      "9335     23.7625                 10.0         0.0  \n",
      "9336     23.7625                 10.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Split the data according to specified date ranges\n",
    "print(\"Splitting data into train, validation, and test sets...\")\n",
    "\n",
    "# Training set: 01.07.2013 to 31.07.2017\n",
    "train_data = all_data[\n",
    "    (all_data['date'] >= train_start) & \n",
    "    (all_data['date'] <= train_end)\n",
    "].copy()\n",
    "\n",
    "# Validation set: 01.08.2017 to 31.07.2018  \n",
    "val_data = all_data[\n",
    "    (all_data['date'] >= val_start) & \n",
    "    (all_data['date'] <= val_end)\n",
    "].copy()\n",
    "\n",
    "# Test set: 01.08.2018 to 31.07.2019\n",
    "test_data = all_data[\n",
    "    (all_data['date'] >= test_start) & \n",
    "    (all_data['date'] <= test_end)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"Training set: {train_data.shape[0]} samples ({train_data['date'].min().date()} to {train_data['date'].max().date()})\")\n",
    "print(f\"Validation set: {val_data.shape[0]} samples ({val_data['date'].min().date()} to {val_data['date'].max().date()})\")\n",
    "print(f\"Test set: {test_data.shape[0]} samples ({test_data['date'].min().date()} to {test_data['date'].max().date()})\")\n",
    "\n",
    "# Check for missing values in each set\n",
    "print(f\"\\nMissing umsatz values:\")\n",
    "print(f\"Training set: {train_data['umsatz'].isnull().sum()} / {len(train_data)}\")\n",
    "print(f\"Validation set: {val_data['umsatz'].isnull().sum()} / {len(val_data)}\")\n",
    "print(f\"Test set: {test_data['umsatz'].isnull().sum()} / {len(test_data)} (expected - these are prediction targets)\")\n",
    "\n",
    "# Display sample from each set\n",
    "print(f\"\\nSample from training set:\")\n",
    "print(train_data.head(3))\n",
    "print(f\"\\nSample from validation set:\")\n",
    "print(val_data.head(3))\n",
    "print(f\"\\nSample from test set:\")\n",
    "print(test_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbd57a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving datasets to CSV files...\n",
      "âœ… Datasets saved successfully!\n",
      "\n",
      "Files created:\n",
      "- data/train_data.csv\n",
      "- data/val_data.csv\n",
      "- data/test_data.csv\n",
      "- data/complete_dataset.csv\n",
      "\n",
      "ğŸ“Š Final Summary:\n",
      "Training period: 2013-07-01 to 2017-07-31 (7493 samples)\n",
      "Validation period: 2017-08-01 to 2018-07-31 (1841 samples)\n",
      "Test period: 2018-08-01 to 2019-07-30 (1830 samples)\n",
      "Total samples: 11164\n",
      "\n",
      "âœ¨ Ready for model training and evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Save the datasets to CSV files\n",
    "print(\"Saving datasets to CSV files...\")\n",
    "\n",
    "# Save to data folder\n",
    "train_data.to_csv('data/train_data.csv', index=False)\n",
    "val_data.to_csv('data/val_data.csv', index=False)\n",
    "test_data.to_csv('data/test_data.csv', index=False)\n",
    "\n",
    "# Also save the complete combined dataset\n",
    "all_data.to_csv('data/complete_dataset.csv', index=False)\n",
    "\n",
    "print(\"âœ… Datasets saved successfully!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- data/train_data.csv\")\n",
    "print(\"- data/val_data.csv\") \n",
    "print(\"- data/test_data.csv\")\n",
    "print(\"- data/complete_dataset.csv\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Final Summary:\")\n",
    "print(f\"Training period: 2013-07-01 to 2017-07-31 ({train_data.shape[0]} samples)\")\n",
    "print(f\"Validation period: 2017-08-01 to 2018-07-31 ({val_data.shape[0]} samples)\")\n",
    "print(f\"Test period: 2018-08-01 to 2019-07-30 ({test_data.shape[0]} samples)\")\n",
    "print(f\"Total samples: {train_data.shape[0] + val_data.shape[0] + test_data.shape[0]}\")\n",
    "print(f\"\\nâœ¨ Ready for model training and evaluation!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
